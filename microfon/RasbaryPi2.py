import os
import numpy as np
import torch
import torch.nn as nn
import librosa
import warnings
from sklearn.preprocessing import LabelEncoder
import time
import threading
import socket
import struct

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
PORTS = [5000, 5001, 5002, 5003]
TARGET_SAMPLE_RATE = 44100
N_MFCC = 40
MODEL_PATH = 'sound_classifier_model.pth'
BUFFER_SIZE = 44100 * 2  # 2 —Å–µ–∫—É–Ω–¥—ã –∞—É–¥–∏–æ
MAX_PACKET_SIZE = 4096
DROPOUT_RATE = 0.6
DATA_DIRS = {
    'train': 'train',
    'valid': 'valid',
    'test': 'test'
}

class SoundClassifier:
    def __init__(self):
        self.le = LabelEncoder()
        self.model = None
        self.running = True
        self.lock = threading.Lock()
        self.audio_buffers = {port: np.array([], dtype=np.float32) for port in PORTS}
        self.last_predictions = {}
        self.sample_rates = {}
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—É—Ç–µ–π –∫ –¥–∞–Ω–Ω—ã–º
        self.data_dir = DATA_DIRS['train']
        self.valid_dir = DATA_DIRS['valid']
        self.test_dir = DATA_DIRS['test']
        
        if not self.load_model():  # –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏
            self.init_training()    # –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞
            
        self.init_network()

    # üîÑ –ü–µ—Ä–µ–º–µ—â–µ–Ω –º–µ—Ç–æ–¥ save_model –≤—ã—à–µ load_model
    def save_model(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –¥–∏—Å–∫"""
        try:
            torch.save({
                'model_state_dict': self.model.state_dict(),
                'le_classes': self.le.classes_,
                'sample_rates': self.sample_rates,
                'input_size': N_MFCC,
                'num_classes': len(self.le.classes_)
            }, MODEL_PATH)
            print(f"–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {MODEL_PATH}")
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {str(e)}")
            raise

    def load_model(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —Å –¥–∏—Å–∫–∞"""
        if os.path.exists(MODEL_PATH):
            try:
                checkpoint = torch.load(
                    MODEL_PATH,
                    map_location='cpu',
                    weights_only=False
                )
                self.le.classes_ = checkpoint['le_classes']
                self.sample_rates = checkpoint.get('sample_rates', {})
                
                self.model = nn.Sequential(
                    nn.Linear(checkpoint['input_size'], 512),
                    nn.BatchNorm1d(512),
                    nn.ReLU(),
                    nn.Dropout(DROPOUT_RATE),
                    nn.Linear(512, 256),
                    nn.BatchNorm1d(256),
                    nn.ReLU(),
                    nn.Dropout(DROPOUT_RATE),
                    nn.Linear(256, 128),
                    nn.BatchNorm1d(128),
                    nn.ReLU(),
                    nn.Dropout(DROPOUT_RATE),
                    nn.Linear(128, 64),
                    nn.BatchNorm1d(64),
                    nn.ReLU(),
                    nn.Dropout(DROPOUT_RATE),
                    nn.Linear(64, checkpoint['num_classes'])
                )
                self.model.load_state_dict(checkpoint['model_state_dict'])
                print(f"–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ {MODEL_PATH}")
                return True
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {str(e)}")
                return False
        print("–§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return False

    def init_training(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ –º–æ–¥–µ–ª–∏"""
        print("\n" + "="*60)
        print("–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞! –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è...")
        print("="*60 + "\n")
        
        try:
            self.load_data()
            self.create_model()
            self.train(num_epochs=250)
            self.save_model()  # üîÑ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –≤—ã–∑–æ–≤
            print("\n–û–±—É—á–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!\n")
            self.load_model()
        except Exception as e:
            print(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏: {str(e)}")
            exit(1)

    def load_data(self):
        def load_from_dir(dir_path):
            if not os.path.exists(dir_path):
                raise FileNotFoundError(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è {dir_path} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                
            X, y = [], []
            file_count = 0
            start_time = time.time()
            
            try:
                for label in os.listdir(dir_path):
                    if not self.running:
                        raise KeyboardInterrupt
                        
                    label_dir = os.path.join(dir_path, label)
                    if not os.path.isdir(label_dir):
                        print(f"–ü—Ä–æ–ø—É—Å–∫–∞–µ–º {label_dir} - –Ω–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è")
                        continue
                        
                    print(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–ª–∞—Å—Å–∞: {label}")
                    files = [f for f in os.listdir(label_dir) if f.endswith('.wav')]
                    if not files:
                        print(f"–í–Ω–∏–º–∞–Ω–∏–µ: –Ω–µ—Ç .wav —Ñ–∞–π–ª–æ–≤ –≤ {label_dir}")
                        continue
                        
                    for file in files:
                        try:
                            if not self.running:
                                raise KeyboardInterrupt
                                
                            file_path = os.path.join(label_dir, file)
                            file_count += 1
                            
                            audio, sr = librosa.load(file_path, sr=None, mono=True)
                            if sr != TARGET_SAMPLE_RATE:
                                audio = librosa.resample(audio, orig_sr=sr, target_sr=TARGET_SAMPLE_RATE)
                                
                            with warnings.catch_warnings():
                                warnings.simplefilter("ignore")
                                mfcc = librosa.feature.mfcc(
                                    y=audio,
                                    sr=TARGET_SAMPLE_RATE,
                                    n_mfcc=N_MFCC,
                                    n_fft=2048,
                                    hop_length=512
                                )
                                
                            X.append(np.mean(mfcc.T, axis=0))
                            y.append(label)
                            
                            if file_count % 10 == 0:
                                elapsed = time.time() - start_time
                                print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {file_count} —Ñ–∞–π–ª–æ–≤ ({elapsed:.1f} —Å–µ–∫)")
                                
                        except KeyboardInterrupt:
                            print("\n–ü—Ä–µ—Ä—ã–≤–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö...")
                            self.running = False
                            raise
                            
                        except Exception as e:
                            print(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {file_path}: {str(e)}")
                            continue
                            
            except KeyboardInterrupt:
                print("\n–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
                self.running = False
                raise
                
            print(f"–£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ {file_count} —Ñ–∞–π–ª–æ–≤")
            return np.array(X, dtype=np.float32), np.array(y)

        try:
            for path in [self.data_dir, self.valid_dir, self.test_dir]:
                if not os.path.exists(path):
                    raise FileNotFoundError(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è {path} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")

            print("\n–ó–∞–≥—Ä—É–∑–∫–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
            self.X, self.y = load_from_dir(self.data_dir)
            self.y_encoded = self.le.fit_transform(self.y)
            
            print("\n–ó–∞–≥—Ä—É–∑–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
            self.X_valid, self.y_valid = load_from_dir(self.valid_dir)
            self.y_encoded_valid = self.le.transform(self.y_valid)
            
            print("\n–ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
            self.X_test, self.y_test = load_from_dir(self.test_dir)
            self.y_encoded_test = self.le.transform(self.y_test)
            
            print("\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞:")
            self._print_dataset_stats("–¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ", self.y)
            self._print_dataset_stats("–í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ", self.y_valid)
            self._print_dataset_stats("–¢–µ—Å—Ç–æ–≤—ã–µ", self.y_test)
            
        except KeyboardInterrupt:
            print("\n–ü–æ–ª–Ω–æ–µ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö")
            self.running = False
            raise
            
        except Exception as e:
            print(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö: {str(e)}")
            self.running = False
            raise

    def _print_dataset_stats(self, name, labels):
        unique, counts = np.unique(labels, return_counts=True)
        print(f"{name} –¥–∞–Ω–Ω—ã–µ:")
        for label, count in zip(unique, counts):
            print(f"  {label}: {count} –ø—Ä–∏–º–µ—Ä–æ–≤")
        print(f"–í—Å–µ–≥–æ: {len(labels)} –ø—Ä–∏–º–µ—Ä–æ–≤\n")

    def create_model(self):
        input_size = N_MFCC
        num_classes = len(self.le.classes_)
        self.model = nn.Sequential(
            nn.Linear(input_size, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(),
            nn.Dropout(DROPOUT_RATE),
            nn.Linear(512, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(),
            nn.Dropout(DROPOUT_RATE),
            nn.Linear(256, 128),
            nn.BatchNorm1d(128),
            nn.ReLU(),
            nn.Dropout(DROPOUT_RATE),
            nn.Linear(128, 64),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.Dropout(DROPOUT_RATE),
            nn.Linear(64, num_classes)
        )
        self.criterion = nn.CrossEntropyLoss()
        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=0.001, weight_decay=1e-4)
        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
            self.optimizer, 
            mode='min', 
            factor=0.5, 
            patience=3,
            verbose=True
        )

    def train(self, num_epochs=250):
        X_tensor = torch.tensor(self.X, dtype=torch.float32)
        y_tensor = torch.tensor(self.y_encoded, dtype=torch.long)
    
        train_losses = []
        valid_losses = []
        train_accuracies = []
        valid_accuracies = []
        learning_rates = []
    
        try:
            for epoch in range(num_epochs):
                if not self.running:
                    raise KeyboardInterrupt
                
            # –û–±—É—á–µ–Ω–∏–µ
                self.model.train()
                self.optimizer.zero_grad()
                outputs = self.model(X_tensor)
                loss = self.criterion(outputs, y_tensor)
                loss.backward()
                self.optimizer.step()
            
            # –†–∞—Å—á–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç–∏ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏
                _, preds = torch.max(outputs, 1)
                correct = (preds == y_tensor).sum().item()
                train_accuracy = correct / len(y_tensor) * 100
            
                train_losses.append(loss.item())
                train_accuracies.append(train_accuracy)
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è
                self.model.eval()
                with torch.no_grad():
                    valid_outputs = self.model(torch.tensor(self.X_valid, dtype=torch.float32))
                    valid_loss = self.criterion(valid_outputs, torch.tensor(self.y_encoded_valid, dtype=torch.long))
                
                # –†–∞—Å—á–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
                    _, valid_preds = torch.max(valid_outputs, 1)
                    valid_correct = (valid_preds == torch.tensor(self.y_encoded_valid, dtype=torch.long)).sum().item()
                    valid_accuracy = valid_correct / len(self.y_encoded_valid) * 100
                
                    valid_losses.append(valid_loss.item())
                    valid_accuracies.append(valid_accuracy)
            
                learning_rates.append(self.optimizer.param_groups[0]['lr'])
            
                print(f"–≠–ø–æ—Ö–∞ [{epoch+1}/{num_epochs}] | "
                    f"–ü–æ—Ç–µ—Ä—è: {loss.item():.4f} | –í–∞–ª–∏–¥–∞—Ü–∏—è: {valid_loss.item():.4f} | "
                    f"–¢–æ—á–Ω–æ—Å—Ç—å: {train_accuracy:.2f}% | –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {valid_accuracy:.2f}%")

        except KeyboardInterrupt:
            print("\n–û–±—É—á–µ–Ω–∏–µ –ø—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
            self.running = False
        
        finally:
            self.analyze_training(
                train_losses, 
                valid_losses,
                train_accuracies,
                valid_accuracies,
                learning_rates
            )


    def analyze_training(self, train_losses, valid_losses, train_accuracies, valid_accuracies, learning_rates):
        print("\n" + "="*60)
        print("–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –æ–±—É—á–µ–Ω–∏—è:")
        print("="*60)
    
    # –ê–Ω–∞–ª–∏–∑ —Ç–æ—á–Ω–æ—Å—Ç–∏
        max_train_acc = max(train_accuracies)
        min_train_acc = min(train_accuracies)
        final_train_acc = train_accuracies[-1]
    
        max_valid_acc = max(valid_accuracies)
        min_valid_acc = min(valid_accuracies)
        final_valid_acc = valid_accuracies[-1]
    
        print(f"\n–¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å:")
        print(f"  –ù–∞—á–∞–ª—å–Ω–∞—è: {train_accuracies[0]:.2f}%")
        print(f"  –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è: {max_train_acc:.2f}% (—ç–ø–æ—Ö–∞ {train_accuracies.index(max_train_acc)+1})")
        print(f"  –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è: {min_train_acc:.2f}% (—ç–ø–æ—Ö–∞ {train_accuracies.index(min_train_acc)+1})")
        print(f"  –§–∏–Ω–∞–ª—å–Ω–∞—è: {final_train_acc:.2f}%")
    
        print(f"\n–í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å:")
        print(f"  –ù–∞—á–∞–ª—å–Ω–∞—è: {valid_accuracies[0]:.2f}%")
        print(f"  –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è: {max_valid_acc:.2f}% (—ç–ø–æ—Ö–∞ {valid_accuracies.index(max_valid_acc)+1})")
        print(f"  –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è: {min_valid_acc:.2f}% (—ç–ø–æ—Ö–∞ {valid_accuracies.index(min_valid_acc)+1})")
        print(f"  –§–∏–Ω–∞–ª—å–Ω–∞—è: {final_valid_acc:.2f}%")
    
    # –ì—Ä–∞—Ñ–∏–∫ —Ç–æ—á–Ω–æ—Å—Ç–∏
        print("\n–î–∏–Ω–∞–º–∏–∫–∞ —Ç–æ—á–Ω–æ—Å—Ç–∏:")
        for epoch, (train_acc, valid_acc) in enumerate(zip(train_accuracies, valid_accuracies)):
            diff = valid_acc - train_acc
            status = "‚Üë‚Üë" if diff > 5 else "‚Üë‚Üì" if diff < -5 else "‚âà"
            print(f"–≠–ø–æ—Ö–∞ {epoch+1:2d}: Train {train_acc:6.2f}% | Valid {valid_acc:6.2f}% | –†–∞–∑–Ω–∏—Ü–∞ {diff:+5.2f}% {status}")
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        print("\n–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
        if final_valid_acc < 60:
            print("  ‚ñ∏ –ù–∏–∑–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å! –ü–æ–ø—Ä–æ–±—É–π—Ç–µ:")
            print("    - –£–≤–µ–ª–∏—á–∏—Ç—å —Ä–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞")
            print("    - –î–æ–±–∞–≤–∏—Ç—å –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—é –∞—É–¥–∏–æ")
            print("    - –ò–∑–º–µ–Ω–∏—Ç—å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –º–æ–¥–µ–ª–∏")
        elif final_valid_acc < 80:
            print("  ‚ñ∏ –°—Ä–µ–¥–Ω—è—è —Ç–æ—á–Ω–æ—Å—Ç—å. –í–æ–∑–º–æ–∂–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è:")
            print("    - –ù–∞—Å—Ç—Ä–æ–∏—Ç—å –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã (LR, —Å–ª–æ–∏)")
            print("    - –î–æ–±–∞–≤–∏—Ç—å —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é")
        else:
            print("  ‚ñ∏ –û—Ç–ª–∏—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç! –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é")
    
        print("="*60 + "\n")

    def load_model(self):
        if os.path.exists(MODEL_PATH):
            try:
                checkpoint = torch.load(
                    MODEL_PATH,
                    map_location='cpu',
                    weights_only=False
                )
                self.le.classes_ = checkpoint['le_classes']
                self.sample_rates = checkpoint.get('sample_rates', {})
                
                self.model = nn.Sequential(
                    nn.Linear(checkpoint['input_size'], 512),
                    nn.BatchNorm1d(512),
                    nn.ReLU(),
                    nn.Dropout(DROPOUT_RATE),
                    nn.Linear(512, 256),
                    nn.BatchNorm1d(256),
                    nn.ReLU(),
                    nn.Dropout(DROPOUT_RATE),
                    nn.Linear(256, 128),
                    nn.BatchNorm1d(128),
                    nn.ReLU(),
                    nn.Dropout(DROPOUT_RATE),
                    nn.Linear(128, 64),
                    nn.BatchNorm1d(64),
                    nn.ReLU(),
                    nn.Dropout(DROPOUT_RATE),
                    nn.Linear(64, checkpoint['num_classes'])
                )
                self.model.load_state_dict(checkpoint['model_state_dict'])
                print(f"–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ {MODEL_PATH}")
                return True
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {str(e)}")
                return False
        print("–§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return False

    def init_network(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ç–µ–≤—ã—Ö —Å–æ–∫–µ—Ç–æ–≤"""
        self.sockets = {}
        for port in PORTS:
            sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
            sock.bind(('0.0.0.0', port))
            self.sockets[port] = sock
            print(f"–°–æ–∫–µ—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –Ω–∞ –ø–æ—Ä—Ç—É {port}")

    def network_listener(self, port):
        """–ü—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏–µ —Å–µ—Ç–µ–≤–æ–≥–æ –ø–æ—Ä—Ç–∞"""
        sock = self.sockets[port]
        print(f"–°–ª—É—à–∞–µ–º –ø–æ—Ä—Ç {port}...")
        while self.running:
            try:
                data, addr = sock.recvfrom(MAX_PACKET_SIZE)
                self.process_packet(port, data)
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –Ω–∞ –ø–æ—Ä—Ç—É {port}: {str(e)}")

    def process_packet(self, port, data):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–µ—Ç–µ–≤—ã—Ö –ø–∞–∫–µ—Ç–æ–≤"""
        try:
            timestamp = struct.unpack('d', data[:8])[0]
            audio_chunk = np.frombuffer(data[8:], dtype=np.float32)
            
            with self.lock:
                self.audio_buffers[port] = np.concatenate([
                    self.audio_buffers[port], 
                    audio_chunk
                ])[-BUFFER_SIZE:]
                
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–∞–∫–µ—Ç–∞: {str(e)}")

    def predict(self, audio):
   
        try:
            if len(audio) == 0:
                return {'class': 'error', 'confidence': 0, 'dBFS': -np.inf}
            
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ç–∏—à–∏–Ω—É
            if np.all(np.abs(audio) < 1e-6):
                return {'class': 'silence', 'confidence': 0, 'dBFS': -np.inf}

        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∞—É–¥–∏–æ
            audio = librosa.util.normalize(audio)
        
        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ MFCC
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                mfcc = librosa.feature.mfcc(
                    y=audio,
                    sr=TARGET_SAMPLE_RATE,
                    n_mfcc=N_MFCC,
                    n_fft=2048,
                    hop_length=512
                )
            mfcc = np.mean(mfcc.T, axis=0)

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å MFCC
            if np.isnan(mfcc).any() or np.isinf(mfcc).any():
                return {'class': 'error', 'confidence': 0, 'dBFS': -np.inf}

        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            self.model.eval()  # –í–∞–∂–Ω–æ: –ø–µ—Ä–µ–∫–ª—é—á–∞–µ–º –≤ —Ä–µ–∂–∏–º –æ—Ü–µ–Ω–∫–∏
            with torch.no_grad():
                inputs = torch.tensor(mfcc, dtype=torch.float32).unsqueeze(0)
                outputs = self.model(inputs)
                proba = torch.softmax(outputs, dim=1)
                conf, pred = torch.max(proba, 1)
        
        # –†–∞—Å—á–µ—Ç —É—Ä–æ–≤–Ω—è –∑–≤—É–∫–∞
            rms = np.sqrt(np.mean(audio**2))
            dBFS = 20 * np.log10(rms) if rms > 0 else -np.inf

            return {
                'class': self.le.inverse_transform([pred.item()])[0],
                'confidence': conf.item(),
                'dBFS': dBFS
            }
        
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {str(e)}")
            return {'class': 'error', 'confidence': 0, 'dBFS': -np.inf}

# –ú–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—è –º–µ—Ç–æ–¥–∞ process_audio()
    def process_audio(self):
        while self.running:
            try:
                predictions = {}
                for port in PORTS:
                    with self.lock:
                        buffer = self.audio_buffers[port]
                    # –ù–∞–∫–æ–ø–ª–µ–Ω–∏–µ 2 —Å–µ–∫—É–Ω–¥ –∞—É–¥–∏–æ –ø–µ—Ä–µ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π
                        if len(buffer) >= BUFFER_SIZE:
                            audio = buffer[-BUFFER_SIZE:]  # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 2 —Å–µ–∫—É–Ω–¥—ã
                            self.audio_buffers[port] = np.array([], dtype=np.float32)
                            predictions[port] = self.predict(audio)
                
                if predictions:
                    self.last_predictions = {
                        i+1: pred for i, (port, pred) in enumerate(predictions.items())
                    }
                    
                    sector = self.determine_sector()
                    print("\n" + "="*60)
                    print(f"{'–°–∏—Å—Ç–µ–º–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –¥—Ä–æ–Ω–æ–≤':^60}")
                    print("="*60)
                    print(f"\n–û–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–π —Å–µ–∫—Ç–æ—Ä: \033[1m{sector}\033[0m\n")
                    
                    for port, pred in predictions.items():
                        status = "–î–†–û–ù –û–ë–ù–ê–†–£–ñ–ï–ù!" if pred['class'] == 'class1' else "–§–æ–Ω–æ–≤—ã–π —à—É–º"
                        confidence = f"{pred['confidence']:.1%}".rjust(8)
                        dBFS = f"{pred['dBFS']:+.1f} dBFS".rjust(12)
                        
                        color = "\033[92m" if pred['class'] == 'class1' else "\033[93m"
                        reset = "\033[0m"
                        
                        print(f"–ü–æ—Ä—Ç {port}:")
                        print(f"{color}‚îú‚îÄ –°—Ç–∞—Ç—É—Å: {status}{reset}")
                        print(f"‚îú‚îÄ –£—Ä–æ–≤–µ–Ω—å –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç–∏: {confidence}")
                        print(f"‚îî‚îÄ –£—Ä–æ–≤–µ–Ω—å –∑–≤—É–∫–∞:    {dBFS}")
                    print("="*60)
                
                time.sleep(1)
                
            except KeyboardInterrupt:
                self.running = False
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}")

    def determine_sector(self):
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–µ–∫—Ç–æ—Ä–∞ –ø–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º"""
        predictions = self.last_predictions
        required_devices = [1, 2, 3, 4]

        for dev_id in required_devices:
            if dev_id not in predictions:
                return "–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ (–Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö)"

        device_classes = {}
        for dev_id in required_devices:
            pred = predictions[dev_id]
            if pred['class'] == 'error':
                return "–û—à–∏–±–∫–∞ –≤ –¥–∞–Ω–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞"
            
            try:
                class_num = int(pred['class'].replace('class', ''))
                device_classes[dev_id] = class_num
            except:
                return f"–û—à–∏–±–∫–∞ –∫–ª–∞—Å—Å–∞: {pred['class']}"

        conditions = [
            (device_classes[1] == 1 and device_classes[2] == 1 and 
             device_classes[4] == 1 and device_classes[3] == 2, "–°–í–ï–†–•–£-–°–õ–ï–í–ê"),
            (device_classes[1] == 1 and device_classes[2] == 1 and 
             device_classes[3] == 1 and device_classes[4] == 2, "–°–í–ï–†–•–£-–°–ü–†–ê–í–ê"),
            (device_classes[1] == 1 and device_classes[3] == 1 and 
             device_classes[4] == 1 and device_classes[2] == 2, "–°–ù–ò–ó–£"),
            (device_classes[2] == 1 and device_classes[3] == 1 and 
             device_classes[4] == 1 and device_classes[1] == 2, "–û—à–∏–±–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"),
            (device_classes[2] == 2 and device_classes[3] == 2 and 
             device_classes[4] == 2 and device_classes[1] == 1, "–û—à–∏–±–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
        ]

        for condition, sector in conditions:
            if condition:
                return sector

        if all(cls == 1 for cls in device_classes.values()):
            sound_levels = {dev_id: predictions[dev_id]['dBFS'] for dev_id in required_devices}
            max_device = max(sound_levels, key=lambda k: sound_levels[k])
            remaining_devices = sorted([d for d in required_devices if d != max_device])
            
            combination = ''.join(map(str, remaining_devices))
            sectors = {
                '123': "–°–í–ï–†–•–£-–°–ü–†–ê–í–ê",
                '134': "–°–ù–ò–ó–£",
                '124': "–°–í–ï–†–•–£-–°–õ–ï–í–ê",
                '234': "–û–®–ò–ë–ö–ê –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–ò"
            }
            
            return sectors.get(combination, f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–æ–º–±–∏–Ω–∞—Ü–∏—è: {combination}")

        return "–ù–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–π —Å–µ–∫—Ç–æ—Ä"

if __name__ == "__main__":
    classifier = SoundClassifier()
    
    # –ó–∞–ø—É—Å–∫ —Å–µ—Ç–µ–≤—ã—Ö –ø–æ—Ç–æ–∫–æ–≤
    listeners = []
    for port in PORTS:
        thread = threading.Thread(
            target=classifier.network_listener,
            args=(port,),
            daemon=True
        )
        thread.start()
        listeners.append(thread)
    
    # –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏
    try:
        classifier.process_audio()
    finally:
        print("\n–û—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞...")
        for sock in classifier.sockets.values():
            sock.close()
        print("–°–µ—Ä–≤–µ—Ä —É—Å–ø–µ—à–Ω–æ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω.")